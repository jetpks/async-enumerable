prelude: |
  require 'async/enumerable'
  
  # Simulate IO side effect operation
  # Scale down delay for larger collections to avoid timeouts
  def process_item(n, size = 100)
    delay = case size
            when 1..100 then rand / 1000.0      # 0-1ms
            when 101..1000 then rand / 5000.0   # 0-0.2ms
            else rand / 50000.0                 # 0-0.02ms for 10000
            end
    sleep(delay)
    # Side effect: would normally write to file, database, etc.
    n * 2
  end
  
  array_10 = (1..10).to_a
  array_100 = (1..100).to_a
  array_1000 = (1..1000).to_a
  array_10000 = (1..10000).to_a

benchmark:
  sync_10: |
    array_10.each { |n| process_item(n, 10) }
  
  async_10: |
    array_10.async.each { |n| process_item(n, 10) }
  
  sync_100: |
    array_100.each { |n| process_item(n, 100) }
  
  async_100: |
    array_100.async.each { |n| process_item(n, 100) }
  
  sync_1000: |
    array_1000.each { |n| process_item(n, 1000) }
  
  async_1000: |
    array_1000.async.each { |n| process_item(n, 1000) }
  
  async_1000_limited: |
    array_1000.async(max_fibers: 100).each { |n| process_item(n, 1000) }
  
  sync_10000: |
    array_10000.each { |n| process_item(n, 10000) }
  
  async_10000: |
    array_10000.async.each { |n| process_item(n, 10000) }
  
  async_10000_limited: |
    array_10000.async(max_fibers: 100).each { |n| process_item(n, 10000) }